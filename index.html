<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>KeyMPs</title>
    <script type="text/javascript" async
            src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <link href="https://fonts.googleapis.com/css2?family=Playfair+Display:wght@400&family=Crimson Pro:wght@400&family=Crimson+Pro:wght@400&family=Cormorant+Garamond:wght@400&family=Libre+Baskerville:wght@400&display=swap" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.11/clipboard.min.js"></script>
    <script>
        document.addEventListener('DOMContentLoaded', () => {
            // Initialize ClipboardJS for all copy buttons
            const clipboard = new ClipboardJS('.copy-button');
    
            // Optional: Add feedback for successful/failed copy actions
            clipboard.on('success', (e) => {
                console.log('Text copied successfully:', e.text);
                e.clearSelection();
            });
            clipboard.on('error', (e) => {
                console.error('Copy failed:', e.action);
            });
    
            // Standardize height for .text-box elements
            const textBoxes = document.querySelectorAll('.text-box');
            let maxHeightTextBox = 0;
            textBoxes.forEach((textBox) => {
                textBox.style.height = 'auto'; // Reset height
                const contentHeight = textBox.scrollHeight;
                maxHeightTextBox = Math.max(maxHeightTextBox, contentHeight);
            });
            textBoxes.forEach((textBox) => {
                textBox.style.height = `${maxHeightTextBox}px`;
            });
    
            // Standardize height for .text-box-merge elements
            const textBoxesMerge = document.querySelectorAll('.text-box-merge');
            let maxHeightMerge = 0;
            textBoxesMerge.forEach((textBox) => {
                textBox.style.height = 'auto'; // Reset height
                const contentHeight = textBox.scrollHeight;
                maxHeightMerge = Math.max(maxHeightMerge, contentHeight);
            });
            textBoxesMerge.forEach((textBox) => {
                textBox.style.height = `${maxHeightMerge}px`;
            });
    
            // Add smooth scrolling with offset for navigation links
            document.querySelectorAll('nav a').forEach(anchor => {
                anchor.addEventListener('click', function (e) {
                    e.preventDefault(); // Prevent default anchor behavior
                    const targetId = this.getAttribute('href').substring(1); // Remove the '#'
    
                    if (targetId === 'home') {
                        // Scroll to the very top for Home link
                        window.scrollTo({
                            top: 0,
                            behavior: 'smooth'
                        });
                    } else {
                        // Scroll with offset for other links (including dropdown items)
                        const targetElement = document.getElementById(targetId);
                        const offset = targetId === 'videos' ? 60 : 60; // Same offset for all non-home links
                        const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - offset;
    
                        window.scrollTo({
                            top: targetPosition,
                            behavior: 'smooth'
                        });
                    }
                });
            });
        });
    </script>



<style>
    body {
        line-height: 1.6;
        margin: 0;
        padding: 50px 0 50px 0;
        background-color: #fff;
        font-family: Georgia, serif;
        width: 100%;
    }
    .content {
        max-width: 650px;
        margin: 20px auto;
        padding: 0 20px;
    }
    
    h1 {
        color: #000000;
        max-width: 650px;
        margin: 20px auto;
        text-align: left;
        font-family: 'Cormorant Garamond', Cochin;
        font-weight: 400;
        font-size: 30px;
    }
    h1 .title-highlight {
        font-size: 70px;
    }
    h2 {
        color: #000000;
        font-family: 'Crimson Pro';
        font-weight: 400;
        font-size: 26px;
        text-align: center;
    }
    h3 {
        color: #000000;
        font-family: 'Crimson Pro';
        font-weight: 400;
        font-size: 22px;
    }
    video {
        margin: 10px;
    }
    .video-grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
        gap: 20px;
        width: 65%;
        margin: 0 auto;
    }
    .video-grid div {
        text-align: center;
    }
    .author-grid {
        display: grid;
        grid-template-columns: repeat(6, 1fr);
        gap: 10px;
        text-align: center;
        margin: 20px auto;
        max-width: 650px;
        border-top: 1px solid #ccc;
        border-bottom: 1px solid #ccc;
        padding: 10px 0;
    }
    .author {
        font-size: 15px;
        text-align: left;
        color: #000;
        font-family: 'Crimson Pro', serif;
    }
    .author span {
        display: block;
        font-size: 14px;
        color: #000000;
    }
    .author a {
        text-decoration: none;
        color: #5e5e5e;
    }
    .author a:hover {
        text-decoration: underline;
    }
    .date {
        text-align: left;
        font-size: 15px;
        font-family: 'Crimson Pro', serif;
    }
    .links {
        text-align: left;
        font-size: 15px;
        font-family: 'Crimson Pro', serif;
    }
    .arxiv-link a {
        color: #ff0000;
        text-decoration: none;
    }
    .arxiv-link a:hover {
        text-decoration: underline;
    }
    .code-link a {
        color: #2600ff;
        text-decoration: none;
    }
    .code-link a:hover {
        text-decoration: underline;
    }
    .grid-container {
        display: grid;
        grid-template-columns: repeat(2, 1fr);
        grid-template-rows: auto auto;
        gap: 20px;
        margin: 20px auto;
        max-width: 650px;
    }
    .image-grid {
        display: grid;
        grid-template-columns: repeat(2, 1fr);
        gap: 20px;
        margin: 20px auto;
        max-width: 650px;
        align-items: start; /* Align items at the top */
    }
    .text-box-container {
        display: flex;
        flex-direction: column;
        justify-content: flex-start; /* Ensure content aligns to the top */
    }
    .copy-bar {
        background-color: #f1f1f1;
        border: 1px solid #ccc;
        border-bottom: none;
        border-radius: 5px 5px 0 0;
        padding: 5px 10px;
        display: flex;
        justify-content: flex-end;
    }
    .copy-button {
        padding: 5px 10px;
        font-size: 12px;
        font-family: 'Crimson Pro', serif;
        color: #fff;
        background-color: #007BFF;
        border: none;
        border-radius: 3px;
        cursor: pointer;
    }
    .copy-button:hover {
        background-color: #0056b3;
    }
    .text-box {
        width: 100%;
        border: 1px solid #ccc;
        border-radius: 0 0 5px 5px;
        padding: 10px 10px 0 10px;
        font-family: 'Crimson Pro', serif;
        font-size: 14px;
        background-color: #f9f9f9;
        overflow-y: auto;
        resize: none;
        box-sizing: border-box;
        white-space: pre-wrap;
        word-wrap: break-word;
        height: 150px;
    }
    .text-box-merge {
        width: 100%;
        border: 1px solid #ccc;
        border-radius: 0 0 5px 5px;
        padding: 10px 10px 0 10px;
        font-family: 'Crimson Pro', serif;
        font-size: 14px;
        background-color: #f9f9f9;
        overflow-y: auto;
        resize: none;
        box-sizing: border-box;
        white-space: pre-wrap;
        word-wrap: break-word;
        height: 150px;
    }
    h2.content, h3.content {
        width: inherit; /* Inherit the dynamic width of the parent container */
        max-width: 55%; /* Match the max width of the video-grid */
        margin: 0 auto; /* Center align the element itself */
        text-align: center; /* Align the text inside the element to the left */
    }
    h2.content{
        padding-top: 10px;
    }
    h3.content{
        padding-top: 10px;
    }
    .prompt-description {
        text-align: center;
    }
    html {
        scroll-behavior: smooth;
    }
    nav {
    position: fixed;
    top: 0;
    width: 100%;
    background-color: rgba(199, 199, 199, 0.3); /* Semi-transparent light gray */
    backdrop-filter: blur(10px); /* Blur effect */
    -webkit-backdrop-filter: blur(10px); /* Safari support */
    padding: 10px 20px;
    z-index: 1000;
    box-sizing: border-box;
}
    nav ul {
        list-style: none;
        display: flex;
        justify-content: flex-end;
        margin: 0 auto; /* Center the ul within the nav */
        padding: 0;
        max-width: 650px; /* Matches content max-width for alignment */
    }
    nav li {
        margin-left: 20px;
    }
    nav a {
        text-decoration: none;
        color: #000;
    }
    nav a:hover {
        text-decoration: underline;
    }
    .dropdown {
        position: relative;
    }
    .dropdown-content {
        display: none;
        position: absolute;
        background-color: #f1f1f1;
        min-width: 160px;
        box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.2);
        z-index: 1001; /* Ensure dropdown appears above other content */
        list-style: none;
        padding: 0;
        margin: 0;
    }
    .dropdown-content li {
        margin: 0; /* Override margin-left from nav li */
    }
    .dropdown-content a {
        color: #000;
        padding: 12px 16px;
        text-decoration: none;
        display: block;
    }
    .dropdown-content a:hover {
        background-color: #ddd;
        text-decoration: underline;
    }
    .dropdown:hover .dropdown-content {
        display: block;
    }
    .dropdown:hover .dropbtn {
        background-color: #ddd; /* Optional: Highlight the Videos button on hover */
    }
</style>
</head>
<body>
    <nav>
        <ul>
            <li><a href="#home">Home</a></li>
            <li><a href="#abstract">Abstract</a></li>
            <li><a href="#method">Method</a></li>
            <li><a href="#implementation">Implementation</a></li>
            <li class="dropdown">
                <a href="#videos" class="dropbtn">Videos</a>
                <ul class="dropdown-content">
                    <li><a href="#simulation">Simulation</a></li>
                    <li><a href="#real-robot">Real Robot</a></li>
                </ul>
            </li>
        </ul>
    </nav>
    <!-- <h1><span class="title-highlight"><strong>KeyMPs</strong></span><br><strong>Key</strong>word Labeled Primitive Selection and<br><strong>Key</strong>point Pairs Generation Guided<br><strong>Movement Primitives</strong><br>Using Vision-Language Models</h1> -->
    <h1><span class="title-highlight"><strong>KeyMPs</strong></span><br>One-Shot Vision-Language Guided Motion Generation by Sequencing DMPs for Occlusion-Rich Tasks</h1>

    <div class="author-grid">
        <div class="author">EDGAR ANAROSSI<span><a href="https://isw3.naist.jp/" target="_blank">NAIST</a></span></div>
        <div class="author">YUHWAN KWON<span><a href="https://isw3.naist.jp/" target="_blank">NAIST</a><br><a href="https://www.kansai-u.ac.jp/Fc_sci/english/department/ee/major.html" target="_blank">Kansai University</a></span></div>
        <div class="author">HIROTAKA TAHARA<span><a href="https://isw3.naist.jp/" target="_blank">NAIST</a><br><a href="https://www.kobe-kosen.ac.jp/groups/denshi/?page=1&cat=PC%E9%96%A2%E9%80%A3" target="_blank">Kobe Kosen</a></span></div>
        <div class="author">SHOHEI TANAKA<span><a href="https://www.omron.com/sinicx/" target="_blank">OMRON SINIC X Corporation</a></span></div>
        <div class="author">KEISUKE SHIRAI<span><a href="https://www.omron.com/sinicx/" target="_blank">OMRON SINIC X Corporation</a></span></div>
        <div class="author">MASASHI HAMAYA<span><a href="https://www.omron.com/sinicx/" target="_blank">OMRON SINIC X Corporation</a></span></div>
        <div class="author">CHRISTIAN BELTRAN<span><a href="https://www.omron.com/sinicx/" target="_blank">OMRON SINIC X Corporation</a></span></div>
        <div class="author">ATSUSHI HASHIMOTO<span><a href="https://www.omron.com/sinicx/" target="_blank">OMRON SINIC X Corporation</a></span></div>
        <div class="author">TAKAMITSU MATSUBARA<span><a href="https://isw3.naist.jp/" target="_blank">NAIST</a></span></div>
        <div class="date">Jan 15, 2025</div>
        <div class="links">
            <span class="arxiv-link"><a href="#" target="_blank">Arxiv</a></span>
            <br>
            <span class="code-link"><a href="#" target="_blank">Code</a></span>
        </div>
    </div>


    <div class="content">
        <br>
        <br>
        <img src="assets/img/method-overview.png" alt="Method Overview" width="100%">
        <p id="abstract">
            <br>
            Dynamic Movement Primitives (DMPs) provide a flexible framework for encoding smooth robotic movements; however, they face challenges in integrating multimodal inputs commonly used in robotics like vision and language into their framework.
            To fully maximize DMPs' potential, it's crucial to enable DMPs to respond to such multimodal inputs and to also broaden their capability to handle object-focused tasks requiring complex motion planning in one shot, as observation occlusion could easily happen mid-execution in such tasks (e.g. knife occlusion in ingredient cutting, piping bag occlusion in cake icing, hand occlusion in dough kneading, etc.).
            A promising approach is to leverage Vision-Language Models (VLMs), which process multimodal data and grasp high-level concepts.
            However, they typically lack the knowledge and capabilities to directly infer low-level motion details and instead serve as a bridge between high-level instructions and low-level control. 
            To address this limitation, we propose Keyword Labeled Primitive Selection and Keypoint Pairs Generation Guided Movement Primitives (KeyMPs), a framework that combines VLMs with sequencing DMPs.
            KeyMPs use VLMs' high-level reasoning to select a reference primitive through <i>Keyword Labeled Primitive Selection</i> and VLMs' spatial awareness to generate spatial scaling parameters used to generalize the overall motion through <i>Keypoint Pairs Generation</i>, ultimately enabling one-shot vision-language guided motion generation that aligns with the intent expressed in the multimodal input.
            We validate our approach through an occlusion-rich manipulation task, specifically object cutting experiments in both simulated and real-world environments, demonstrating superior performance over other DMP-based methods that integrate VLMs support.
        </p>

        <br>
        <br>
        <br>
        <h2 id="method"><b>Method</b></h2>
        <p>
            Our proposed framework, <strong>KeyMPs</strong>, integrates language and vision inputs to generate executable motions by leveraging VLMs and DMPs. It operates through three stages:
        </p>
        <ol>
            <li>
                <h3>Pre-Processing:</h3>
                <p>
                    The framework begins by collecting two primary types of inputs:
                </p>
                <ul>
                    <li><em>Language input:</em> User-provided instructions.</li>
                    <li><em>Vision input:</em> Environment or object representations from a camera.</li>
                </ul>
                <p>
                    An object detector identifies the object's global coordinates and produces a cropped object image, while the object's height measurement is supplied to the framework.
                    A pixel-based object detection approach determines the global coordinates. Alternative object detection methods are also supported.
                </p>
            </li>
            <li>
                <h3>Contextual processing:</h3>
                <div class="grid-container">
                    <!-- Top Row: Explanations -->
                    <div class="text-box-container">
                        <p class="prompt-description">In <strong>keyword labeled primitive selection</strong>, VLMs employ high-level reasoning to select a reference primitive from a predefined primitive dictionary.</p>
                    </div>
                    <div class="text-box-container">
                        <p class="prompt-description">In <strong>keypoint pairs generation</strong>, VLMs generate 2D keypoint pairs that, combined with the object's height, define the <em>spatial scaling parameters</em> (\( y_0 \) and \( y_{\text{goal}} \)). These are based on combined language and vision inputs.</p>
                    </div>
                    <!-- Bottom Row: Textboxes -->
                    <div class="text-box-container">
                        <div class="copy-bar">
                            <button class="copy-button" data-clipboard-target="#textbox-1">Copy</button>
                        </div>
                        <textarea id="textbox-1" class="text-box" readonly>
You are a 𝑡𝑎𝑠𝑘 and a robot expert. 

You will be provided with an image of an 𝑜𝑏𝑗𝑒𝑐𝑡 and a user input of 𝑑𝑒𝑠𝑖𝑟𝑒𝑑 𝑜𝑢𝑡𝑐𝑜𝑚𝑒. 

Your job is to select the most suitable 𝒑𝒓𝒊𝒎𝒊𝒕𝒊𝒗𝒆 from a list of 𝒑𝒓𝒊𝒎𝒊𝒕𝒊𝒗𝒆 𝒌𝒆𝒚𝒘𝒐𝒓𝒅𝒔 given the type of 𝒐𝒃𝒋𝒆𝒄𝒕 shown in the image and the user’s 𝒅𝒆𝒔𝒊𝒓𝒆𝒅 𝒐𝒖𝒕𝒄𝒐𝒎𝒆. 

Here are the list of 𝑝𝑟𝑖𝑚𝑖𝑡𝑖𝑣𝑒 𝑘𝑒𝑦𝑤𝑜𝑟𝑑𝑠 for this 𝑡𝑎𝑠𝑘 : […] 

Provide me with the 𝑝𝑟𝑖𝑚𝑖𝑡𝑖𝑣𝑒 𝑘𝑒𝑦𝑤𝑜𝑟𝑑 you selected. Here are some examples: …
                        </textarea>
                    </div>
                    <div class="text-box-container">
                        <div class="copy-bar">
                            <button class="copy-button" data-clipboard-target="#textbox-2">Copy</button>
                        </div>
                        <textarea id="textbox-2" class="text-box" readonly>
You are a 𝑡𝑎𝑠𝑘 and a robot expert. You will be provided with an image of an 𝑜𝑏𝑗𝑒𝑐𝑡 and a user input of 𝒅𝒆𝒔𝒊𝒓𝒆𝒅 𝒐𝒖𝒕𝒄𝒐𝒎𝒆. 

Your job is to generate keypoint pairs (lines) design(s) according to the user desired outcome. 

In this 𝑡𝑎𝑠𝑘, the keypoint pairs represent 𝑣𝑒𝑟𝑏 where the starting keypoint represent the start of 𝑣𝑒𝑟𝑏 and the end keypoint represent the end of 𝑣𝑒𝑟𝑏. 

To make sure proper keypoint pairs design generation, follow these steps: 

1. Identify the 𝑜𝑏𝑗𝑒𝑐𝑡 in the image. 

2. Describe the shape of the 𝑜𝑏𝑗𝑒𝑐𝑡 shown in the image (Rectangular? Circular? Object-specific shape?) 

3. Describe your design plan to generate keypoint pairs based on the shape in no.2 and the user input to achieve the 𝒅𝒆𝒔𝒊𝒓𝒆𝒅 𝒐𝒖𝒕𝒄𝒐𝒎𝒆. 

4. Make a python code to generate list of lines (list of list of coordinates) based on the plan in no.3. Make sure the code output a JSON file filled with the keypoint pairs within the range of [0, 1]. Here are some examples: …
                        </textarea>
                    </div>
                </div>
            </li>
            <li>
                <h3>DMPs motion generation:</h3>
                <p>
                    The reference primitive and the <em>spatial scaling parameters</em> are used to create the definitive DMP motion.
                    The motion is generated by iteratively applying each spatial scaling parameter to scale the reference primitive.
                </p>
            </li>
        </ol>
        <p>The rest of the details can be found in our <a href="#">research paper</a>.</p>

        <br>
        <br>
        <br>
        <h2 class="content" id="implementation"><b>Implementation</b></h2>
        <h3 class="content">System Prompt</h3>
        <p>
            For this study, we employed GPT-4o, developed by OpenAI, as the foundational vision-language model (VLM). 
            In our object cutting experiment, we utilized the following system prompt to initialize the VLMs.
        </p>
        <div class="text-box-container">
            <div class="copy-bar">
                <button class="copy-button" data-clipboard-target="#textbox-3">Copy</button>
            </div>
            <textarea id="textbox-3" class="text-box-merge" readonly>
You are a cooking and robotic expert who output values in JSON format.
You will be given 2 inputs, user text input (let's call this in_text) and an image (in_img) of an object filling the image placed.
Your task is to draw cutting lines on in_img using python to satisfy in_text.

First, let's first describe the object in the image:
(1) tell me the dimension of the image and put it in a key called 'img_dim'.
(2) describe the properties of the object. things like the object's name, whether it is cooked or raw, object's hardness, object's elasticity, object's color, object's shape (square? circle? rectangular? object-specific shape?), object's orientation within the image (vertically longer? horizontally longer? diagonal?), object's average length (if not mentioned specifically), and other things you can describe from the image. put this description in a key called 'object_description'. Make sure you try to acquire the information from the image first before relying on your knowledge base. Try to fill in the remaining properties if you can't see it in the image.
Interpret the object orientation through the image dimension, this will later be important on deciding the pattern's rotation.


Second, describe the object in the picture, then describe in detail how you would cut the object on the image into the desired result and put it in a key called 'description'. Create the design pattern using a combination of one or multiple keypoint pairs (lines).
To make sure the plan is correct, 
-in the first sentence describe the user desired outcome (e.g. equal cut, 5 slices, 8 slices, etc)
-in the second sentence describe the type of design you want to use (grid-based or radial-based) (e.g. grid-based where you cut the objects into rows and columns no matter the cuts are combinations of horizontal+vertical cuts or horizontal+diagonal cuts, radial-based where you the cut is specifically cit like a pie). Only use radial cuts on circular shaped objects unless specifically asked.
-in the third sentence describe your plan in detail based on the design type in the previous sentence on how you would cut the object while considering the properties of the object (described in 'object_description') and the user desired outcome.
For example if I asked for 9 equal slices for an object, if the object shape is circular, then cut it using radial cuts on 360/9=40 degree cuts, meanwhile if the object shape is square/rectangular, then cut it using grids (e.g. 3 rows, 3 columns) for 9 equal cuts. 
Notes:
-Try utilizing your knowledge of the object parts ratio to create the cutting pattern if needed.
-When handling cutting plan with some calculation, try to assert that the (number_of_cuts+1)*length_cut==total_length
-You can use just horizontal cuts OR just vertical cuts OR just diagonal cuts OR grids of vertical and horizontal cuts OR other combinations of horizontal, vertical, & diagonal cuts, just make sure it achieves the user desired outcome correctly, you can try different ones for your plan.

Third, Make me a python code based on 'description' which: 
(1) imports the uploaded image as 'temp/test_img_proposed.png'; 
(2) creates a cutting pattern according to 'description' within the range of 0 to 1;
(3) scales said pattern from the previous step according to the image size; 
(4) outputs a list of list of list of the scaled cutting pattern as a JSON file called 'temp/keypoints.json' with the key being 'keypoints'; 
(5) draws the cutting pattern/lines (blue color) on top of the base image (let's call it 'temp/cropped_img.png') using matplotlib and saves it as 'temp/cut_projection.png'
Notes:
-Put all the python code inside a key called 'code' and make sure it's formatted properly so I can run it immediately.
-Use consistent type of quotes for the code (single quote) and for the JSON file (double quote).
-The inner-most list of 'keypoints' contains 2 values of x and y representing a coordinate on the image space where the x axis corresponds to the image columns and the y axis corresponds to the image rows. The list containing the inner-most list contains 2 lists representing a the start and end position of the line. Finally the outer-most list contains multiple of the list representing a line for each of the line in the cutting pattern. So the list's shape is something like this: [[[line1_start_x, line1_start, y], [line1_end_x, line1_end_y]], [[line2_start_x, line2_start, y], [line2_end_x, line2_end_y]], ..., [[lineN_start_x, lineN_start, y], [lineN_end_x, lineN_end_y]]]

Fourth, I also want you to choose what style of cutting is best to cut the object in the image based on the properties you described in 'object_description'. You have 2 options to choose from: either 'downward' for straight-downward cutting for very soft object (e.g. soft cake, jelly, tofu, banana, easy to cut vegetables, etc) or 'sawing' for a sawing motion for harder, crusty, or elastic object (e.g. french bread, raw chicken or beef or pork or other meats, loaf of bread, etc). Explain your reasoning on how you choose a keyword and put it in 'keyword_reason', then put the selected keyword in 'keyword'.

Final reminder, the keys inside the JSON are img_dim, object_description, description, code, keyword, keyword_reason.
            </textarea>
        </div>
    </div>

    
    


    <br>
    <br>
    <br>
    <h2 class="content" id="videos"><b>Videos</b></h2>
    <h3 class="content" id="simulation">Simulation Experiments</h3>
    <div class="video-grid">
        <div>
            <video width="300" autoplay muted loop>
                <source src="assets/vid/sim/3D_gt/proposed_0_0.webm" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <p>"A single horizontal slice in the middle"</p>
        </div>
        <div>
            <video width="300" autoplay muted loop>
                <source src="assets/vid/sim/3D_gt/proposed_1_0.webm" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <p>"I want to eat 1 slice for each day of this week, cut it vertically"</p>
        </div>
        <div>
            <video width="300" autoplay muted loop>
                <source src="assets/vid/sim/3D_gt/proposed_2_0.webm" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <p>"I'm having a party for 10 people, cut 1 slice for each"</p>
        </div>
        <div>
            <video width="300" autoplay muted loop>
                <source src="assets/vid/sim/3D_gt/proposed_3_0.webm" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <p>"Cut it into 8 equal slices"</p>
        </div>
        <div>
            <video width="300" autoplay muted loop>
                <source src="assets/vid/sim/3D_gt/proposed_4_0.webm" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <p>"The object is 10 cm long, cut it vertically into 5 cm slices"</p>
        </div>
        <div>
            <video width="300" autoplay muted loop>
                <source src="assets/vid/sim/3D_gt/proposed_5_0.webm" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <p>"The object is 15 cm long, cut it vertically into 5 cm slices"</p>
        </div>
        <div>
            <video width="300" autoplay muted loop>
                <source src="assets/vid/sim/3D_gt/proposed_6_0.webm" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <p>"The object is 20 cm long, cut it vertically into 5 cm slices"</p>
        </div>
        <div>
            <video width="300" autoplay muted loop>
                <source src="assets/vid/sim/3D_gt/proposed_7_0.webm" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <p>"The object is 25 cm long, cut it vertically into 5 cm slices"</p>
        </div>
        <div>
            <video width="300" autoplay muted loop>
                <source src="assets/vid/sim/3D_gt/proposed_8_0.webm" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <p>"The object is 30 cm long, cut it vertically into 5 cm slices"</p>
        </div>
        <div>
            <video width="300" autoplay muted loop>
                <source src="assets/vid/sim/3D_gt/proposed_9_0.webm" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <p>"Slice the object into 3 parts horizontally"</p>
        </div>
        <div>
            <video width="300" autoplay muted loop>
                <source src="assets/vid/sim/3D_gt/proposed_10_0.webm" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <p>"Slice both tips of the object"</p>
        </div>
        <div>
            <video width="300" autoplay muted loop>
                <source src="assets/vid/sim/3D_gt/proposed_11_0.webm" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <p>"The object is 35 cm long, cut it vertically into 5 cm slices"</p>
        </div>
        <div>
            <video width="300" autoplay muted loop>
                <source src="assets/vid/sim/3D_gt/proposed_12_0.webm" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <p>"The object is 40 cm long, cut it vertically into 5 cm slices"</p>
        </div>
        <div>
            <video width="300" autoplay muted loop>
                <source src="assets/vid/sim/3D_gt/proposed_13_0.webm" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <p>"The object is 40 cm long, cut it vertically into 5 cm slices"</p>
        </div>
        <div>
            <video width="300" autoplay muted loop>
                <source src="assets/vid/sim/3D_gt/proposed_14_0.webm" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <p>"The object is 45 cm long, cut it vertically into 5 cm slices"</p>
        </div>
    </div>
    <br>
    <h3 class="content" id="real-robot">Real Robot Experiments (4x speed)</h3>
    <div class="video-grid">
        <div>
            <video width="300" autoplay muted loop>
                <source src="assets/vid/real/1_chiffon.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <p>"I have 3 guests, cut a few thin slices of the chiffon cake for them."</p>
        </div>
        <div>
            <video width="300" autoplay muted loop>
                <source src="assets/vid/real/2_chiffon.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <p>"I want to eat this chiffon cake for each day this week."</p>
        </div>
        <div>
            <video width="300" autoplay muted loop>
                <source src="assets/vid/real/3_cucumber.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <p>"I want to make tsukemono."</p>
        </div>
        <div>
            <video width="300" autoplay muted loop>
                <source src="assets/vid/real/4_eggplant.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <p>"I want to make wide chips out of this."</p>
        </div>
        <div>
            <video width="300" autoplay muted loop>
                <source src="assets/vid/real/5_baumkuchen.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <p>"Split it into 4."</p>
        </div>
        <div>
            <video width="300" autoplay muted loop>
                <source src="assets/vid/real/6_meat.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <p>"This is a 490g block of meat (length 21cm, width 8cm), the nutrition facts mentioned that every 100g there's 150kcal. Cut me several number of slices in a certain length (below 3cm) just enough if I want to go for a 3km walk after this."</p>
        </div>
        <div>
            <video width="300" autoplay muted loop>
                <source src="assets/vid/real/7_meat.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <p>"This is a block of meat (length 16cm, width 8cm). Cut me 4 2cm slices."</p>
        </div>
        <div>
            <video width="300" autoplay muted loop>
                <source src="assets/vid/real/8_potato.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <p>"Prepare it for fondant potato, this potato is quite small."</p>
        </div>
        <div>
            <video width="300" autoplay muted loop>
                <source src="assets/vid/real/9_potato.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <p>"Cut it into french fries."</p>
        </div>
        <div>
            <video width="300" autoplay muted loop>
                <source src="assets/vid/real/10_banana.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <p>"For banana pancake."</p>
        </div>
    </div>
</body>
</html>
