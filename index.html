<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>KeyMPs: One-Shot Vision-Language Guided Motion Generation by Sequencing DMPs for Occlusion-Rich Tasks</title>
    <link rel="icon" href="assets/favicon_64x64.png" type="image/x-icon">
    <script type="text/javascript" async
            src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <link href="https://fonts.googleapis.com/css2?family=Playfair+Display:wght@400&family=Crimson+Pro:wght@400&family=Cormorant+Garamond:wght@400&family=Libre+Baskerville:wght@400&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/basiclightbox@5.0.4/dist/basicLightbox.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.11/clipboard.min.js"></script>
    <script>
        document.addEventListener('DOMContentLoaded', () => {
            // Initialize ClipboardJS for all copy buttons
            const clipboard = new ClipboardJS('.copy-button');
    
            clipboard.on('success', (e) => {
                console.log('Text copied successfully:', e.text);
                e.clearSelection();
            });
            clipboard.on('error', (e) => {
                console.error('Copy failed:', e.action);
            });
    
            // Standardize height for .text-box elements
            const textBoxes = document.querySelectorAll('.text-box');
            let maxHeightTextBox = 0;
            textBoxes.forEach((textBox) => {
                textBox.style.height = 'auto';
                const contentHeight = textBox.scrollHeight;
                maxHeightTextBox = Math.max(maxHeightTextBox, contentHeight);
            });
            textBoxes.forEach((textBox) => {
                textBox.style.height = `${maxHeightTextBox}px`;
            });
    
            // Standardize height for .text-box-merge elements
            const textBoxesMerge = document.querySelectorAll('.text-box-merge');
            let maxHeightMerge = 0;
            textBoxesMerge.forEach((textBox) => {
                textBox.style.height = 'auto';
                const contentHeight = textBox.scrollHeight;
                maxHeightMerge = Math.max(maxHeightMerge, contentHeight);
            });
            textBoxesMerge.forEach((textBox) => {
                textBox.style.height = `${maxHeightMerge}px`;
            });
    
            // Smooth scrolling with offset for navigation links
            document.querySelectorAll('nav a').forEach(anchor => {
                anchor.addEventListener('click', function (e) {
                    e.preventDefault();
                    const targetId = this.getAttribute('href').substring(1);
    
                    if (targetId === 'home') {
                        window.scrollTo({
                            top: 0,
                            behavior: 'smooth'
                        });
                    } else {
                        const targetElement = document.getElementById(targetId);
                        const offset = 60;
                        const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - offset;
    
                        window.scrollTo({
                            top: targetPosition,
                            behavior: 'smooth'
                        });
                    }
                });
            });

            // Tab switching functionality
            const tabButtons = document.querySelectorAll('.tab-button');
            const tabContents = document.querySelectorAll('.tab-content');
            tabButtons.forEach(button => {
                button.addEventListener('click', () => {
                    const tabId = button.getAttribute('data-tab');
                    tabButtons.forEach(btn => btn.classList.remove('active'));
                    tabContents.forEach(content => content.classList.remove('active'));
                    button.classList.add('active');
                    document.getElementById(tabId).classList.add('active');
                });
            });
            // New submethod tab-switching JavaScript
            const submethodTabButtons = document.querySelectorAll('.submethod-tab-button');
            const submethodTabContents = document.querySelectorAll('.submethod-tab-content');
            submethodTabButtons.forEach(button => {
                button.addEventListener('click', () => {
                    const tabId = button.getAttribute('data-tab');
                    submethodTabButtons.forEach(btn => btn.classList.remove('active'));
                    submethodTabContents.forEach(content => content.classList.remove('active'));
                    button.classList.add('active');
                    document.getElementById(tabId).classList.add('active');
                });
            });

            document.querySelectorAll('img').forEach(img => {
                img.addEventListener('click', () => {
                    // Find the parent <figure> and its <figcaption>, if any
                    const figure = img.closest('figure');
                    const caption = figure ? figure.querySelector('figcaption')?.textContent : '';
                    const captionHtml = caption ? `<figcaption>${caption}</figcaption>` : '';
                    const instance = basicLightbox.create(`
                        <div class="modal">
                            <img class="img-close" src="${img.src}" alt="${img.alt}" style="max-width: 90vw; max-height: 90vh;">
                            ${captionHtml}
                            <a class="lightbox-close" onclick="this.parentElement.parentElement.close()">×</a>
                        </div>
                    `, {
                        onShow: (instance) => {
                            instance.element().querySelector('.lightbox-close').onclick = instance.close;
                            // instance.element().querySelector('.modal').onclick = instance.close;
                        }
                    });
                    instance.show();
                });
            });
        });
    </script>
    <script src="https://cdn.jsdelivr.net/npm/basiclightbox@5.0.4/dist/basicLightbox.min.js"></script>
    <meta name="description" content="KeyMPs: One-Shot Vision-Language Guided Motion Generation by Sequencing DMPs for Occlusion-Rich Tasks. Learn about our framework combining VLMs and DMPs for complex robotic motion generation.">
    <meta name="keywords" content="KeyMPs, robotics, motion generation, DMPs, VLMs, vision-language models, occlusion-rich, one-shot learning">
    <meta name="author" content="EDGAR ANAROSSI, YUHWAN KWON, HIROTAKA TAHARA, SHOHEI TANAKA, KEISUKE SHIRAI, MASASHI HAMAYA, CHRISTIAN BELTRAN, ATSUSHI HASHIMOTO, TAKAMITSU MATSUBARA">
    <style>
        .content p {
            text-align: justify;
        }
        body {
            line-height: 1.6;
            margin: 0;
            padding: 50px 0 50px 0;
            background-color: #fff;
            font-family: Georgia, serif;
            width: 100%;
        }
        .content {
            max-width: 1400px;
            margin: 20px auto;
            padding: 0 20px;
        }
        h1 {
            color: #000000;
            max-width: 1400px;
            margin: 20px auto;
            text-align: left;
            font-family: 'Cormorant Garamond', Cochin;
            font-weight: 400;
            font-size: 30px;
        }
        h1 .title-highlight {
            font-size: 50px;
        }
        h2 {
            color: #000000;
            font-family: 'Crimson Pro';
            font-weight: 400;
            font-size: 26px;
            text-align: center;
        }
        h3 {
            color: #000000;
            font-family: 'Crimson Pro';
            font-weight: 400;
            font-size: 22px;
        }
        video {
            margin: 5px;
            padding: 5px;
        }
        .video-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            /* padding:20px 0 0 0; */
            width: 100%;
            margin: 0 auto;
        }
        .video-grid div {
            text-align: center;
            box-shadow: 0 0 8px rgba(0, 0, 0, 0.2); /* Drop shadow for active button */
        }
        .author-grid {
            display: grid;
            grid-template-columns: repeat(6, 1fr);
            gap: 10px;
            text-align: center;
            margin: 20px auto;
            max-width: 1400px;
            border-top: 1px solid #ccc;
            border-bottom: 1px solid #ccc;
            padding: 10px 0;
        }
        .author {
            font-size: 15px;
            text-align: left;
            color: #000;
            font-family: 'Crimson Pro', serif;
        }
        .author span {
            display: block;
            font-size: 14px;
            color: #000000;
        }
        .author a {
            text-decoration: none;
            color: #5e5e5e;
        }
        .author a:hover {
            text-decoration: underline;
        }
        .date {
            text-align: left;
            font-size: 15px;
            font-family: 'Crimson Pro', serif;
        }
        .links {
            text-align: left;
            font-size: 15px;
            font-family: 'Crimson Pro', serif;
        }
        .arxiv-link a {
            color: #ff0000;
            text-decoration: none;
        }
        .ieee-link a {
            color: #00629b;
            text-decoration: none;
        }
        .arxiv-link a:hover {
            text-decoration: underline;
        }
        .code-link a {
            color: #2600ff;
            text-decoration: none;
        }
        .code-link a:hover {
            text-decoration: underline;
        }
        .grid-container {
            display: grid;
            grid-template-columns: repeat(2, 1fr);
            grid-template-rows: auto auto;
            gap: 20px;
            margin: 20px auto;
            max-width: 1400px;
        }
        .image-grid {
            display: grid;
            grid-template-columns: repeat(2, 1fr);
            gap: 20px;
            margin: 20px auto;
            max-width: 1400px;
            align-items: start;
        }
        .text-box-container {
            display: flex;
            flex-direction: column;
            justify-content: flex-start;
        }
        .copy-bar {
            background-color: #f1f1f1;
            border: 1px solid #ccc;
            border-bottom: none;
            border-radius: 5px 5px 0 0;
            padding: 5px 10px;
            display: flex;
            justify-content: flex-end;
        }
        .copy-button {
            padding: 5px 10px;
            font-size: 12px;
            font-family: 'Crimson Pro', serif;
            color: #fff;
            background-color: #007BFF;
            border: none;
            border-radius: 3px;
            cursor: pointer;
        }
        .copy-button:hover {
            background-color: #0056b3;
        }
        .text-box {
            width: 100%;
            border: 1px solid #ccc;
            border-radius: 0 0 5px 5px;
            padding: 10px 10px 0 10px;
            font-family: 'Crimson Pro', serif;
            font-size: 14px;
            background-color: #f9f9f9;
            overflow-y: auto;
            resize: none;
            box-sizing: border-box;
            white-space: pre-wrap;
            word-wrap: break-word;
            height: 150px;
        }
        .text-box-merge {
            width: 100%;
            border: 1px solid #ccc;
            border-radius: 0 0 5px 5px;
            padding: 10px 10px 0 10px;
            font-family: 'Crimson Pro', serif;
            font-size: 14px;
            background-color: #f9f9f9;
            overflow-y: auto;
            resize: none;
            box-sizing: border-box;
            white-space: pre-wrap;
            word-wrap: break-word;
            height: 150px;
        }
        html {
            scroll-behavior: smooth;
        }
        nav {
            position: fixed;
            top: 0;
            width: 100%;
            background-color: rgba(199, 199, 199, 0.3);
            backdrop-filter: blur(10px);
            -webkit-backdrop-filter: blur(10px);
            padding: 10px 20px;
            z-index: 1000;
            box-sizing: border-box;
        }
        nav ul {
            list-style: none;
            display: flex;
            justify-content: flex-end;
            margin: 0 auto;
            padding: 0;
            max-width: 1400px;
        }
        nav li {
            margin-left: 20px;
        }
        nav a {
            text-decoration: none;
            color: #000;
        }
        nav a:hover {
            text-decoration: underline;
        }
        .tabs {
            max-width: 1400px;
            margin: 0 auto;
        }
        .tab-titles {
            display: flex;
            justify-content: center;
            /* margin-bottom: 20px; */
        }
        .tab-button {
            width: 50%;
            padding: 10px 20px;
            border: 0px solid #ccc;
            background-color: #f1f1f1;
            cursor: pointer;
            font-family: 'Crimson Pro', serif;
            font-size: 20px;
            border-radius: 8px 8px 0px 0px;
            text-align: center; /* Ensure text is centered within each button */
            box-sizing: border-box;
            position: relative; /* For z-index layering */
            z-index: 1;
            transition: background-color 0.3s ease; 
        }
        .tab-button.active {
            background-color: #ffffff;
            border-bottom: none;
            border-radius: 8px 8px 0px 0px ;
            box-shadow: 0 0 8px rgba(0, 0, 0, 0.2); /* Drop shadow for active button */
            z-index: 2;
            transition: background-color 0.3s ease; 
        }
        .tab-button:not(.active):hover {
            background-color: #ccc;
            transition: background-color 0.3s ease; 
        }
        .tab-content {
            display: none;
            border: 0px solid #ccc;
            padding: 20px;
            background-color: #ffffff;
            border-radius: 0px 0px 8px 8px;
            position: relative; /* For z-index layering */
            z-index: 1;
            transition: background-color 0.3s ease; 
        }
        .tab-content.active {
            display: block;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2); /* Drop shadow for active content */
            z-index: 2;
            transition: background-color 0.3s ease; 
        }
        .experiments-section {
            max-width: 1400px;
            margin: 0 auto;
            padding: 0 20px;
        }
        .experiments-section h2, .experiments-section h3 {
            text-align: center;
            margin: 0px 0px 20px 0px;
        }
        figure {
            display: block;
            margin-left: auto;
            margin-right: auto;
            text-align: center;
        }
        img:not(.modal img) {
            display: block;
            margin-left: auto;
            margin-right: auto;
            /* box-shadow: 0 0px 8px rgba(0, 0, 0, 0.2); */
            border-radius: 8px;
            outline: 10px solid transparent;
            outline-offset: 10px;
            cursor: pointer;
            transition: opacity 0.3s ease, transform 0.3s ease, box-shadow 0.3s ease;
        }
        img:not(.modal img):hover {
            opacity: 0.8;
            transform: scale(1.02);
            box-shadow: 0 6px 12px rgba(0, 0, 0, 0.3);
        }
        .content img {
            max-width: 100%;
        }
        figcaption {
            font-family: 'Crimson Pro', serif;
            font-size: 18px;
            color: #000;
            margin-top: 8px;
            max-width: 100%;
            margin-left: auto;
            margin-right: auto;
        }
        .modal figcaption {
            color: #fff;
            font-family: 'Crimson Pro', serif;
            font-size: 24px;
            margin-top: 8px;
            max-width: 90vw;
            margin-left: auto;
            margin-right: auto;
            text-align: center;
        }
        .modal {
            position: relative;
            display: inline-block;
        }
        .lightbox-close {
            position: absolute;
            top: -15px;
            right: -15px;
            font-size: 24px;
            color: #000;
            background: #fff;
            border: 2px solid #000;
            border-radius: 50%;
            width: 30px;
            height: 30px;
            line-height: 30px;
            text-align: center;
            text-decoration: none;
            cursor: pointer;
        }
        .lightbox-close:hover {
            background: #ccc;
        }
        .method-box{
            /* border: 1px solid #ccc; */
            background-color: #fff;
            border-radius: 8px;
            padding-inline-start: 20px;
            padding-inline-end: 20px;
            box-shadow: 0 0px 8px rgba(0, 0, 0, 0.2);
        }
        .rounded-corners{
            border: 1px solid #ccc;
            background-color: #fff;
            border-radius: 8px;
        }
        .video-grid p{
            padding: 5px 20px 20px 20px;
            text-align: center;
            margin-block-start: 0px;
            margin-block-end: 0px;
        }
        .content h3{
            text-align: center;
            margin: 0px 0px 20px 0px;
        }
        .submethod {
            border: 1px solid #ccc;
            background-color: #fff;
            border-radius: 8px;
            padding: 20px 20px;
            text-align: justify;
            box-shadow: 0 0 8px rgba(0, 0, 0, 0.2); /* Drop shadow for active button */
        }
        .submethod-tabs {
            max-width: 1400px;
            margin: 0 auto;
        }
        .submethod-tab-titles {
            display: flex;
            justify-content: center;
            /* margin-bottom: 20px; */
        }
        .submethod-tab-button {
            width: 50%;
            padding: 10px 20px;
            border: 0px solid #ccc;
            background-color: #f1f1f1;
            cursor: pointer;
            font-family: 'Crimson Pro', serif;
            font-size: 20px;
            border-radius: 8px 8px 0px 0px;
            text-align: center; /* Ensure text is centered within each button */
            box-sizing: border-box;
            position: relative; /* For z-index layering */
            z-index: 1;
            transition: background-color 0.3s ease; 
        }
        .submethod-tab-button:not(.active):hover {
            background-color: #ccc;
            transition: background-color 0.3s ease; 
        }
        .submethod-tab-button.active {
            background-color: #ffffff;
            border-bottom: none;
            border-radius: 8px 8px 0px 0px ;
            box-shadow: 0 0 8px rgba(0, 0, 0, 0.2); /* Drop shadow for active button */
            z-index: 2;
            transition: background-color 0.3s ease; 
        }
        .submethod-tab-content {
            display: none;
            border: 0px solid #ccc;
            padding: 20px;
            background-color: #ffffff;
            border-radius: 0px 0px 8px 8px;
            position: relative; /* For z-index layering */
            z-index: 1;
            transition: background-color 0.3s ease; 
        }
        .submethod-tab-content.active {
            display: block;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2); /* Drop shadow for active content */
            z-index: 2;
            transition: background-color 0.3s ease; 
        }
        /* #abstract{
            border: 1px solid #ccc;
            padding: 20px;
            background-color: #fff;
            border-radius: 8px;
        } */
    </style>
    </head>
    <body>
        <nav>
            <ul>
                <li><a href="#home">Home</a></li>
                <li><a href="#abstract">Abstract</a></li>
                <li><a href="#method">Method</a></li>
                <li><a href="#experiments">Experiments</a></li>
            </ul>
        </nav>

        <div style="padding:0 20px">
            <h1><span class="title-highlight"><strong>KeyMPs</strong></span><br>One-Shot Vision-Language Guided Motion Generation by Sequencing DMPs for Occlusion-Rich Tasks</h1>

            <div class="author-grid">
                <div class="author">EDGAR ANAROSSI<span><a href="https://isw3.naist.jp/" target="_blank">NAIST</a> - <a href="https://sites.google.com/view/naist-robot-learning-jp/%E3%83%9B%E3%83%BC%E3%83%A0" target="_blank">Robot Learning Lab</a></span></div>
                <div class="author">YUHWAN KWON<span><a href="https://isw3.naist.jp/" target="_blank">NAIST</a> - <a href="https://sites.google.com/view/naist-robot-learning-jp/%E3%83%9B%E3%83%BC%E3%83%A0" target="_blank">Robot Learning Lab</a><br><a href="https://www.kansai-u.ac.jp/Fc_sci/english/department/ee/major.html" target="_blank">Kansai University</a></span></div>
                <div class="author">HIROTAKA TAHARA<span><a href="https://isw3.naist.jp/" target="_blank">NAIST</a> - <a href="https://sites.google.com/view/naist-robot-learning-jp/%E3%83%9B%E3%83%BC%E3%83%A0" target="_blank">Robot Learning Lab</a><br><a href="https://www.kobe-kosen.ac.jp/groups/denshi/?page=1&cat=PC%E9%96%A2%E9%80%A3" target="_blank">Kobe Kosen</a></span></div>
                <div class="author">SHOHEI TANAKA<span><a href="https://www.omron.com/sinicx/" target="_blank">OMRON SINIC X Corporation</a></span></div>
                <div class="author">KEISUKE SHIRAI<span><a href="https://www.omron.com/sinicx/" target="_blank">OMRON SINIC X Corporation</a></span></div>
                <div class="author">MASASHI HAMAYA<span><a href="https://www.omron.com/sinicx/" target="_blank">OMRON SINIC X Corporation</a></span></div>
                <div class="author">CHRISTIAN BELTRAN<span><a href="https://www.omron.com/sinicx/" target="_blank">OMRON SINIC X Corporation</a></span></div>
                <div class="author">ATSUSHI HASHIMOTO<span><a href="https://www.omron.com/sinicx/" target="_blank">OMRON SINIC X Corporation</a></span></div>
                <div class="author">TAKAMITSU MATSUBARA<span><a href="https://isw3.naist.jp/" target="_blank">NAIST</a> - <a href="https://sites.google.com/view/naist-robot-learning-jp/%E3%83%9B%E3%83%BC%E3%83%A0" target="_blank">Robot Learning Lab</a></span></div>
                <div class="author">Jan 15, 2025</div>
                <div class="links">
                    <span class="ieee-link"><a href="" target="_blank">IEEE</a></span><br>
                    <span class="arxiv-link"><a href="https://arxiv.org/abs/2504.10011" target="_blank">Arxiv</a></span>
                </div>
            </div>
        </div>

        <div class="content">
            <figure>
                <img src="assets/img/method-overview.png" alt="Method Overview" width="80%">
                <figcaption>Overview of the KeyMPs framework for vision-language guided motion generation.</figcaption>
            </figure>
            <br>
            <h2 id="abstract"><b>Abstract</b></h2>
            <p>
                Dynamic Movement Primitives (DMPs) provide a flexible framework for encoding smooth robotic movements; however, they face challenges in integrating multimodal inputs commonly used in robotics like vision and language into their framework.
                To fully maximize DMPs' potential, it's crucial to enable DMPs to respond to such multimodal inputs and to also broaden their capability to handle object-focused tasks requiring complex motion planning in one shot, as observation occlusion could easily happen mid-execution in such tasks (e.g. knife occlusion in ingredient cutting, piping bag occlusion in cake icing, hand occlusion in dough kneading, etc.).
                A promising approach is to leverage Vision-Language Models (VLMs), which process multimodal data and grasp high-level concepts.
                However, they typically lack the knowledge and capabilities to directly infer low-level motion details and instead serve as a bridge between high-level instructions and low-level control. 
                To address this limitation, we propose Keyword Labeled Primitive Selection and Keypoint Pairs Generation Guided Movement Primitives (KeyMPs), a framework that combines VLMs with sequencing DMPs.
                KeyMPs use VLMs' high-level reasoning to select a reference primitive through <i>Keyword Labeled Primitive Selection</i> and VLMs' spatial awareness to generate spatial scaling parameters used to generalize the overall motion through <i>Keypoint Pairs Generation</i>, ultimately enabling one-shot vision-language guided motion generation that aligns with the intent expressed in the multimodal input.
                We validate our approach through an occlusion-rich manipulation task, specifically object cutting experiments in both simulated and real-world environments, demonstrating superior performance over other DMP-based methods that integrate VLMs support.
            </p>

            <br>
            <h2 id="method"><b>Method</b></h2>
            <p>
                Our proposed framework, <strong>KeyMPs</strong>, integrates language and vision inputs to generate executable motions by leveraging VLMs and DMPs. It operates through three stages:
            </p>
            <div class="method-box" style="padding:20px">
                <h3><u>1. Pre-Processing:</u></h3>
                <div class="submethod">
                    <p>
                        The framework begins by collecting two primary types of inputs:
                    </p>
                    <ul>
                        <li><em>Language input:</em> User-provided instructions.</li>
                        <li><em>Vision input:</em> Environment or object representations from a camera.</li>
                    </ul>
                    <p>
                        An object detector identifies the object's global coordinates and produces a cropped object image, while the object's height measurement is supplied to the framework.
                        A pixel-based object detection approach determines the global coordinates. Alternative object detection methods are also supported.
                    </p>
                    <figure>
                        <img src="assets/img/method-1-input.png" alt="Pre-Processing" width="60%" onclick="showLightbox()">
                        <figcaption>Pre-processing of vision and textual input data.</figcaption>
                    </figure>
                </div>

                <br>
                <h3><u>2. Contextual processing:</u></h3>
                <div class="submethod-tabs">
                    <div class="submethod-tab-titles">
                        <button class="submethod-tab-button active" data-tab="keyword-selection">Keyword Labeled Primitive Selection</button>
                        <button class="submethod-tab-button" data-tab="keypoint-generation">Keypoint Pairs Generation</button>
                    </div>
                    <div class="submethod-tab-content active" id="keyword-selection">
                        <div class="submethod">
                            <p class="prompt-description">In <strong>keyword labeled primitive selection</strong>, VLMs employ high-level reasoning to select a reference primitive from a predefined primitive dictionary.</p>
                            <figure>
                                <img src="assets/img/method-2-keyword.png" alt="Keyword Labeled Primitive Selection" width="62%">
                                <figcaption>Selection of DMP primitive using VLMs.</figcaption>
                            </figure>
                            <div class="copy-bar">
                                <button class="copy-button" data-clipboard-target="#textbox-1">Copy</button>
                            </div>
                            <textarea id="textbox-1" class="text-box" readonly>
You are a 𝑡𝑎𝑠𝑘 and a robot expert. 

You will be provided with an image of an 𝑜𝑏𝑗𝑒𝑐𝑡 and a user input of 𝑑𝑒𝑠𝑖𝑟𝑒𝑑 𝑜𝑢𝑡𝑐𝑜𝑚𝑒. 

Your job is to select the most suitable 𝒑𝒓𝒊𝒎𝒊𝒕𝒊𝒗𝒆 from a list of 𝒑𝒓𝒊𝒎𝒊𝒕𝒊𝒗𝒆 𝒌𝒆𝒚𝒘𝒐𝒓𝒅𝒔 given the type of 𝒐𝒃𝒋𝒆𝒄𝒕 shown in the image and the user’s 𝒅𝒆𝒔𝒊𝒓𝒆𝒅 𝒐𝒖𝒕𝒄𝒐𝒎𝒆. 

Here are the list of 𝑝𝑟𝑖𝑚𝑖𝑡𝑖𝑣𝑒 𝑘𝑒𝑦𝑤𝑜𝑟𝑑𝑠 for this 𝑡𝑎𝑠𝑘 : […] 

Provide me with the 𝑝𝑟𝑖𝑚𝑖𝑡𝑖𝑣𝑒 𝑘𝑒𝑦𝑤𝑜𝑟𝑑 you selected. Here are some examples: …
                            </textarea>
                        </div>
                    </div>
                    <div class="submethod-tab-content" id="keypoint-generation">
                        <div class="submethod">
                            <p class="prompt-description">In <strong>keypoint pairs generation</strong>, VLMs generate 2D keypoint pairs that, combined with the object's height, define the <em>spatial scaling parameters</em> (\( y_0 \) and \( y_{\text{goal}} \)). These are based on combined language and vision inputs.</p>
                                <figure>
                                    <img src="assets/img/method-2-keypoint.png" alt="Keypoint Pairs Generation" width="62%">
                                    <figcaption>Generation of keypoint pairs design using VLMs.</figcaption>
                                </figure>
                            <div class="copy-bar">
                                    <button class="copy-button" data-clipboard-target="#textbox-2">Copy</button>
                                </div>
                                <textarea id="textbox-2" class="text-box" readonly>
You are a 𝑡𝑎𝑠𝑘 and a robot expert. You will be provided with an image of an 𝑜𝑏𝑗𝑒𝑐𝑡 and a user input of 𝒅𝒆𝒔𝒊𝒓𝒆𝒅 𝒐𝒖𝒕𝒄𝒐𝒎𝒆. 

Your job is to generate keypoint pairs (lines) design(s) according to the user desired outcome. 

In this 𝑡𝑎𝑠𝑘, the keypoint pairs represent 𝑣𝑒𝑟𝑏 where the starting keypoint represent the start of 𝑣𝑒𝑟𝑏 and the end keypoint represent the end of 𝑣𝑒𝑟𝑏. 

To make sure proper keypoint pairs design generation, follow these steps: 

1. Identify the 𝑜𝑏𝑗𝑒𝑐𝑡 in the image. 

2. Describe the shape of the 𝑜𝑏𝑗𝑒𝑐𝑡 shown in the image (Rectangular? Circular? Object-specific shape?) 

3. Describe your design plan to generate keypoint pairs based on the shape in no.2 and the user input to achieve the 𝒅𝒆𝒔𝒊𝒓𝒆𝒅 𝒐𝒖𝒕𝒄𝒐𝒎𝒆. 

4. Make a python code to generate list of lines (list of list of coordinates) based on the plan in no.3. Make sure the code output a JSON file filled with the keypoint pairs within the range of [0, 1]. Here are some examples: …
                                </textarea>
                        </div>
                    </div>
                </div>
                <br>
                <h3><u>3. DMPs motion generation:</u></h3>
                <div class="submethod" style="padding:20px">
                    <p>
                        The reference primitive and the <em>spatial scaling parameters</em> are used to create the definitive DMP motion.
                        The motion is generated by iteratively applying each spatial scaling parameter to scale the reference primitive.
                    </p>
                    <figure>
                        <img src="assets/img/method-3-sequencing.png" alt="DMP-based Motion Generation" width="60%" onclick="showLightbox()">
                        <figcaption>Sequencing of scaled DMP primitives to create the final complex motion.</figcaption>
                    </figure>
                </div>
            </div>
            <p>The rest of the details can be found in our <a href="#">research paper</a>.</p>
        </div>
        <br>
        <div class="experiments-section">
            <h2 id="experiments"><b>Experiments</b></h2>
            <div class="tabs">
                <div class="tab-titles">
                    <button class="tab-button active" data-tab="cutting">Object Cutting Task</button>
                    <button class="tab-button" data-tab="icing">Cake Icing Task</button>
                </div>
                <div class="tab-content active" id="cutting">
                    <h3><u>Task Description</u></h3>
                    <div class="submethod">
                        <p>
                            The object cutting task involves generating a cutting pattern for an object based on user instructions. 
                            The task is designed to test the framework's ability to handle occlusion-rich environments and generate precise cutting motions.
                            This task is performed in both simulated and real-world environments.
                            A simulation environment is created using the IsaacGym platform.
                        </p>
                        <figure>
                            <img src="assets/img/env-cutting.jpg" alt="Object Cutting Task Simulation Environment" width="50%" onclick="showLightbox()">
                            <figcaption>IsaacGym simulation environment of the Object Cutting Task.</figcaption>
                        </figure>
                    </div>
                    

                    <br>
                    <br>
                    <h3><u>System Prompt</u></h3>
                    <div class="submethod" style="padding:20px">
                        <p>
                            For this study, we employed GPT-4o, developed by OpenAI, as the foundational vision-language model (VLM). 
                            In our object cutting experiment, we utilized the following system prompt to initialize the VLMs.
                        </p>
                        <div class="text-box-container">
                            <div class="copy-bar">
                                <button class="copy-button" data-clipboard-target="#textbox-3">Copy</button>
                            </div>
                            <textarea id="textbox-3" class="text-box-merge" readonly>
You are a cooking and robotic expert who output values in JSON format.
You will be given 2 inputs, user text input (let's call this in_text) and an image (in_img) of an object filling the image placed.
Your task is to draw cutting lines on in_img using python to satisfy in_text.

First, let's first describe the object in the image:
(1) tell me the dimension of the image and put it in a key called 'img_dim'.
(2) describe the properties of the object. things like the object's name, whether it is cooked or raw, object's hardness, object's elasticity, object's color, object's shape (square? circle? rectangular? object-specific shape?), object's orientation within the image (vertically longer? horizontally longer? diagonal?), object's average length (if not mentioned specifically), and other things you can describe from the image. put this description in a key called 'object_description'. Make sure you try to acquire the information from the image first before relying on your knowledge base. Try to fill in the remaining properties if you can't see it in the image.
Interpret the object orientation through the image dimension, this will later be important on deciding the pattern's rotation.

Second, describe the object in the picture, then describe in detail how you would cut the object on the image into the desired result and put it in a key called 'description'. Create the design pattern using a combination of one or multiple keypoint pairs (lines).
To make sure the plan is correct, 
-in the first sentence describe the user desired outcome (e.g. equal cut, 5 slices, 8 slices, etc)
-in the second sentence describe the type of design you want to use (grid-based or radial-based) (e.g. grid-based where you cut the objects into rows and columns no matter the cuts are combinations of horizontal+vertical cuts or horizontal+diagonal cuts, radial-based where you the cut is specifically cit like a pie). Only use radial cuts on circular shaped objects unless specifically asked.
-in the third sentence describe your plan in detail based on the design type in the previous sentence on how you would cut the object while considering the properties of the object (described in 'object_description') and the user desired outcome.
For example if I asked for 9 equal slices for an object, if the object shape is circular, then cut it using radial cuts on 360/9=40 degree cuts, meanwhile if the object shape is square/rectangular, then cut it using grids (e.g. 3 rows, 3 columns) for 9 equal cuts. 
Notes:
-Try utilizing your knowledge of the object parts ratio to create the cutting pattern if needed.
-When handling cutting plan with some calculation, try to assert that the (number_of_cuts+1)*length_cut==total_length
-You can use just horizontal cuts OR just vertical cuts OR just diagonal cuts OR grids of vertical and horizontal cuts OR other combinations of horizontal, vertical, & diagonal cuts, just make sure it achieves the user desired outcome correctly, you can try different ones for your plan.

Third, Make me a python code based on 'description' which: 
(1) imports the uploaded image as 'temp/test_img_proposed.png'; 
(2) creates a cutting pattern according to 'description' within the range of 0 to 1;
(3) scales said pattern from the previous step according to the image size; 
(4) outputs a list of list of list of the scaled cutting pattern as a JSON file called 'temp/keypoints.json' with the key being 'keypoints'; 
(5) draws the cutting pattern/lines (blue color) on top of the base image (let's call it 'temp/cropped_img.png') using matplotlib and saves it as 'temp/cut_projection.png'
Notes:
-Put all the python code inside a key called 'code' and make sure it's formatted properly so I can run it immediately.
-Use consistent type of quotes for the code (single quote) and for the JSON file (double quote).
-The inner-most list of 'keypoints' contains 2 values of x and y representing a coordinate on the image space where the x axis corresponds to the image columns and the y axis corresponds to the image rows. The list containing the inner-most list contains 2 lists representing a the start and end position of the line. Finally the outer-most list contains multiple of the list representing a line for each of the line in the cutting pattern. So the list's shape is something like this: [[[line1_start_x, line1_start, y], [line1_end_x, line1_end_y]], [[line2_start_x, line2_start, y], [line2_end_x, line2_end_y]], ..., [[lineN_start_x, lineN_start, y], [lineN_end_x, lineN_end_y]]]

Fourth, I also want you to choose what style of cutting is best to cut the object in the image based on the properties you described in 'object_description'. You have 2 options to choose from: either 'downward' for straight-downward cutting for very soft object (e.g. soft cake, jelly, tofu, banana, easy to cut vegetables, etc) or 'sawing' for a sawing motion for harder, crusty, or elastic object (e.g. french bread, raw chicken or beef or pork or other meats, loaf of bread, etc). Explain your reasoning on how you choose a keyword and put it in 'keyword_reason', then put the selected keyword in 'keyword'.

Final reminder, the keys inside the JSON are img_dim, object_description, description, code, keyword, keyword_reason.
                            </textarea>
                        </div>
                    </div>
                    
                    
                    <br>
                    <br>
                    <h3 id="simulation"><u>Videos (Simulation)</u></h3>
                    <div class="video-grid">
                        <div class="rounded-corners">
                            <video width="300" autoplay muted loop>
                                <source src="assets/vid/sim/3D_gt/proposed_0_0.webm" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <p class="vidcaption">"A single horizontal slice in the middle"</p>
                        </div>
                        <div class="rounded-corners">
                            <video width="300" autoplay muted loop>
                                <source src="assets/vid/sim/3D_gt/proposed_1_0.webm" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <p class="vidcaption">"I want to eat 1 slice for each day of this week, cut it vertically"</p>
                        </div>
                        <div class="rounded-corners">
                            <video width="300" autoplay muted loop>
                                <source src="assets/vid/sim/3D_gt/proposed_2_0.webm" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <p class="vidcaption">"I'm having a party for 10 people, cut 1 slice for each"</p>
                        </div>
                        <div class="rounded-corners">
                            <video width="300" autoplay muted loop>
                                <source src="assets/vid/sim/3D_gt/proposed_3_0.webm" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <p class="vidcaption">"Cut it into 8 equal slices"</p>
                        </div>
                        <div class="rounded-corners">
                            <video width="300" autoplay muted loop>
                                <source src="assets/vid/sim/3D_gt/proposed_4_0.webm" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <p class="vidcaption">"The object is 10 cm long, cut it vertically into 5 cm slices"</p>
                        </div>
                        <div class="rounded-corners">
                            <video width="300" autoplay muted loop>
                                <source src="assets/vid/sim/3D_gt/proposed_5_0.webm" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <p class="vidcaption">"The object is 15 cm long, cut it vertically into 5 cm slices"</p>
                        </div>
                        <div class="rounded-corners">
                            <video width="300" autoplay muted loop>
                                <source src="assets/vid/sim/3D_gt/proposed_6_0.webm" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <p class="vidcaption">"The object is 20 cm long, cut it vertically into 5 cm slices"</p>
                        </div>
                        <div class="rounded-corners">
                            <video width="300" autoplay muted loop>
                                <source src="assets/vid/sim/3D_gt/proposed_7_0.webm" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <p class="vidcaption">"The object is 25 cm long, cut it vertically into 5 cm slices"</p>
                        </div>
                        <div class="rounded-corners">
                            <video width="300" autoplay muted loop>
                                <source src="assets/vid/sim/3D_gt/proposed_8_0.webm" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <p class="vidcaption">"The object is 30 cm long, cut it vertically into 5 cm slices"</p>
                        </div>
                        <div class="rounded-corners">
                            <video width="300" autoplay muted loop>
                                <source src="assets/vid/sim/3D_gt/proposed_9_0.webm" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <p class="vidcaption">"Slice the object into 3 parts horizontally"</p>
                        </div>
                        <div class="rounded-corners">
                            <video width="300" autoplay muted loop>
                                <source src="assets/vid/sim/3D_gt/proposed_10_0.webm" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <p class="vidcaption">"Slice both tips of the object"</p>
                        </div>
                        <div class="rounded-corners">
                            <video width="300" autoplay muted loop>
                                <source src="assets/vid/sim/3D_gt/proposed_11_0.webm" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <p class="vidcaption">"The object is 35 cm long, cut it vertically into 5 cm slices"</p>
                        </div>
                        <div class="rounded-corners">
                            <video width="300" autoplay muted loop>
                                <source src="assets/vid/sim/3D_gt/proposed_12_0.webm" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <p class="vidcaption">"The object is 40 cm long, cut it vertically into 5 cm slices"</p>
                        </div>
                        <div class="rounded-corners">
                            <video width="300" autoplay muted loop>
                                <source src="assets/vid/sim/3D_gt/proposed_13_0.webm" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <p class="vidcaption">"The object is 40 cm long, cut it vertically into 5 cm slices"</p>
                        </div>
                        <div class="rounded-corners">
                            <video width="300" autoplay muted loop>
                                <source src="assets/vid/sim/3D_gt/proposed_14_0.webm" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <p class="vidcaption">"The object is 45 cm long, cut it vertically into 5 cm slices"</p>
                        </div>
                    </div>
                    <br>
                    <br>
                    <h3 id="real-robot"><u>Videos (Real World Setting) [4x speed]</u></h3>
                    <div class="video-grid">
                        <div class="rounded-corners">
                            <video width="300" autoplay muted loop>
                                <source src="assets/vid/real/1_chiffon.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <p class="vidcaption">"I have 3 guests, cut a few thin slices of the chiffon cake for them."</p>
                        </div>
                        <div class="rounded-corners">
                            <video width="300" autoplay muted loop>
                                <source src="assets/vid/real/2_chiffon.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <p class="vidcaption">"I want to eat this chiffon cake for each day this week."</p>
                        </div>
                        <div class="rounded-corners">
                            <video width="300" autoplay muted loop>
                                <source src="assets/vid/real/3_cucumber.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <p class="vidcaption">"I want to make tsukemono."</p>
                        </div>
                        <div class="rounded-corners">
                            <video width="300" autoplay muted loop>
                                <source src="assets/vid/real/4_eggplant.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <p class="vidcaption">"I want to make wide chips out of this."</p>
                        </div>
                        <div class="rounded-corners">
                            <video width="300" autoplay muted loop>
                                <source src="assets/vid/real/5_baumkuchen.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <p class="vidcaption">"Split it into 4."</p>
                        </div>
                        <div class="rounded-corners">
                            <video width="300" autoplay muted loop>
                                <source src="assets/vid/real/6_meat.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <p class="vidcaption">"This is a 490g block of meat (length 21cm, width 8cm), the nutrition facts mentioned that every 100g there's 150kcal. Cut me several number of slices in a certain length (below 3cm) just enough if I want to go for a 3km walk after this."</p>
                        </div>
                        <div class="rounded-corners">
                            <video width="300" autoplay muted loop>
                                <source src="assets/vid/real/7_meat.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <p class="vidcaption">"This is a block of meat (length 16cm, width 8cm). Cut me 4 2cm slices."</p>
                        </div>
                        <div class="rounded-corners">
                            <video width="300" autoplay muted loop>
                                <source src="assets/vid/real/8_potato.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <p class="vidcaption">"Prepare it for fondant potato, this potato is quite small."</p>
                        </div>
                        <div class="rounded-corners">
                            <video width="300" autoplay muted loop>
                                <source src="assets/vid/real/9_potato.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <p class="vidcaption">"Cut it into french fries."</p>
                        </div>
                        <div class="rounded-corners">
                            <video width="300" autoplay muted loop>
                                <source src="assets/vid/real/10_banana.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <p class="vidcaption">"For banana pancake."</p>
                        </div>
                    </div>
                </div>
                <div class="tab-content" id="icing">
                    <h3><u>Task Description</u></h3>
                    <div class="submethod">
                        <p>
                            The cake icing task involves generating a cake icing pattern for a cake based on user instructions.
                            The task is designed to test VLMs' ability on generating intricate icing patterns.
                            This task is performed in a simulated environment created using the IsaacGym platform.
                        </p>
                        <figure>
                            <img src="assets/img/env-icing.jpg" alt="Object Cutting Task Simulation Environment" width="50%" onclick="showLightbox()">
                            <figcaption>IsaacGym simulation environment of the Cake Icing Task.</figcaption>
                        </figure>
                    </div>
                    

                    <br>
                    <br>
                    <h3><u>System Prompt</u></h3>
                    <div class="submethod" style="padding:20px">
                        <p>
                            For this study, we employed GPT-4o, developed by OpenAI, as the foundational vision-language model (VLM). 
                            In our object cutting experiment, we utilized the following system prompt to initialize the VLMs.
                        </p>
                        <div class="text-box-container">
                            <div class="copy-bar">
                                <button class="copy-button" data-clipboard-target="#textbox-3">Copy</button>
                            </div>
                            <textarea id="textbox-3" class="text-box-merge" readonly>
You are a cooking and robotic expert who output values in JSON format.
You will be given 2 inputs, user text input (let's call this in_text) and an image (in_img) of an object filling the image placed.
Your task is to draw cutting lines on in_img using python to satisfy in_text.

First, let's first describe the object in the image:
(1) tell me the dimension of the image and put it in a key called 'img_dim'.
(2) describe the properties of the object. things like the object's name, whether it is cooked or raw, object's hardness, object's elasticity, object's color, object's shape (square? circle? rectangular? object-specific shape?), object's orientation within the image (vertically longer? horizontally longer? diagonal?), object's average length (if not mentioned specifically), and other things you can describe from the image. put this description in a key called 'object_description'. Make sure you try to acquire the information from the image first before relying on your knowledge base. Try to fill in the remaining properties if you can't see it in the image.
Interpret the object orientation through the image dimension, this will later be important on deciding the pattern's rotation.

Second, describe the object in the picture, then describe in detail how you would cut the object on the image into the desired result and put it in a key called 'description'. Create the design pattern using a combination of one or multiple keypoint pairs (lines).
To make sure the plan is correct, 
-in the first sentence describe the user desired outcome (e.g. equal cut, 5 slices, 8 slices, etc)
-in the second sentence describe the type of design you want to use (grid-based or radial-based) (e.g. grid-based where you cut the objects into rows and columns no matter the cuts are combinations of horizontal+vertical cuts or horizontal+diagonal cuts, radial-based where you the cut is specifically cit like a pie). Only use radial cuts on circular shaped objects unless specifically asked.
-in the third sentence describe your plan in detail based on the design type in the previous sentence on how you would cut the object while considering the properties of the object (described in 'object_description') and the user desired outcome.
For example if I asked for 9 equal slices for an object, if the object shape is circular, then cut it using radial cuts on 360/9=40 degree cuts, meanwhile if the object shape is square/rectangular, then cut it using grids (e.g. 3 rows, 3 columns) for 9 equal cuts. 
Notes:
-Try utilizing your knowledge of the object parts ratio to create the cutting pattern if needed.
-When handling cutting plan with some calculation, try to assert that the (number_of_cuts+1)*length_cut==total_length
-You can use just horizontal cuts OR just vertical cuts OR just diagonal cuts OR grids of vertical and horizontal cuts OR other combinations of horizontal, vertical, & diagonal cuts, just make sure it achieves the user desired outcome correctly, you can try different ones for your plan.

Third, Make me a python code based on 'description' which: 
(1) imports the uploaded image as 'temp/test_img_proposed.png'; 
(2) creates a cutting pattern according to 'description' within the range of 0 to 1;
(3) scales said pattern from the previous step according to the image size; 
(4) outputs a list of list of list of the scaled cutting pattern as a JSON file called 'temp/keypoints.json' with the key being 'keypoints'; 
(5) draws the cutting pattern/lines (blue color) on top of the base image (let's call it 'temp/cropped_img.png') using matplotlib and saves it as 'temp/cut_projection.png'
Notes:
-Put all the python code inside a key called 'code' and make sure it's formatted properly so I can run it immediately.
-Use consistent type of quotes for the code (single quote) and for the JSON file (double quote).
-The inner-most list of 'keypoints' contains 2 values of x and y representing a coordinate on the image space where the x axis corresponds to the image columns and the y axis corresponds to the image rows. The list containing the inner-most list contains 2 lists representing a the start and end position of the line. Finally the outer-most list contains multiple of the list representing a line for each of the line in the cutting pattern. So the list's shape is something like this: [[[line1_start_x, line1_start, y], [line1_end_x, line1_end_y]], [[line2_start_x, line2_start, y], [line2_end_x, line2_end_y]], ..., [[lineN_start_x, lineN_start, y], [lineN_end_x, lineN_end_y]]]

Fourth, I also want you to choose what style of cutting is best to cut the object in the image based on the properties you described in 'object_description'. You have 2 options to choose from: either 'downward' for straight-downward cutting for very soft object (e.g. soft cake, jelly, tofu, banana, easy to cut vegetables, etc) or 'sawing' for a sawing motion for harder, crusty, or elastic object (e.g. french bread, raw chicken or beef or pork or other meats, loaf of bread, etc). Explain your reasoning on how you choose a keyword and put it in 'keyword_reason', then put the selected keyword in 'keyword'.

Final reminder, the keys inside the JSON are img_dim, object_description, description, code, keyword, keyword_reason.
                            </textarea>
                        </div>
                    </div>
                    
                    
                    <br>
                    <br>
                    <h3 id="simulation"><u>Videos (Simulation)</u></h3>
                    <div class="video-grid">
                        <div class="rounded-corners">
                            <video width="300" autoplay muted loop>
                                <source src="assets/vid/sim/cake/1.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <p class="vidcaption">"Put 15 icings around the cake, provide some space from the cake edge and between each icing."</p>
                        </div>
                        <div class="rounded-corners">
                            <video width="300" autoplay muted loop>
                                <source src="assets/vid/sim/cake/2.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <p class="vidcaption">"Make 2 layers of icing around the cake, provide some space from the edges and between layers."</p>
                        </div>
                        <div class="rounded-corners">
                            <video width="300" autoplay muted loop>
                                <source src="assets/vid/sim/cake/3.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <p class="vidcaption">"Combine 2 types of designs, icing dots around the cake and a spiral icing line design."</p>
                        </div>
                        <div class="rounded-corners">
                            <video width="300" autoplay muted loop>
                                <source src="assets/vid/sim/cake/4.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <p class="vidcaption">"I'm having my 27th birthday, put the digits on the cake using seven-segment characters as icing lines."</p>
                        </div>
                        <div class="rounded-corners">
                            <video width="300" autoplay muted loop>
                                <source src="assets/vid/sim/cake/5.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <p class="vidcaption">"Draw a 5-pointed star using lines in the middle of the cake."</p>
                        </div>
                        <div class="rounded-corners">
                            <video width="300" autoplay muted loop>
                                <source src="assets/vid/sim/cake/6.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <p class="vidcaption">"Create a simple interesting design."</p>
                        </div>
                        <div class="rounded-corners">
                            <video width="300" autoplay muted loop>
                                <source src="assets/vid/sim/cake/7.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <p class="vidcaption">"Create a simple interesting design."</p>
                        </div>
                        <div class="rounded-corners">
                            <video width="300" autoplay muted loop>
                                <source src="assets/vid/sim/cake/8.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <p class="vidcaption">"I want to put 1 dot of icing on the middle of each of the 10 slices."</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        
    </body>
</html>